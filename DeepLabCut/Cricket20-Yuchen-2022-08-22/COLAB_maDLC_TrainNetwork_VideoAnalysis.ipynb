{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MMathisLab/DeepLabCut/blob/master/examples/COLAB_maDLC_TrainNetwork_VideoAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# DeepLabCut 2.2 Toolbox - COLAB\n",
    "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1590444465547-SHXODUII311HEE407IL6/ke17ZwdGBToddI8pDm48kE4VnnB9_j2k1VP236ADqAFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQg9Vf0owGyf3dhfDKy8SxMujaKmp2B54Sb3VS1rO76Whq-cUhHVuKFlGUXsU9tJk/ezgif.com-video-to-gif.gif?format=1500w)\n",
    "\n",
    "https://github.com/DeepLabCut/DeepLabCut\n",
    "\n",
    "This notebook illustrates how to, for multi-animal projects, use the cloud-based GPU to:\n",
    "- create a multi-animal training set\n",
    "- train a network\n",
    "- evaluate a network\n",
    "- cross evaluate inference parameters\n",
    "- analyze novel videos\n",
    "- assemble tracklets\n",
    "- create quality check plots\n",
    "\n",
    "###This notebook assumes you already have a project folder with labeled data! \n",
    "\n",
    "This notebook demonstrates the necessary steps to use DeepLabCut for your own project.\n",
    "\n",
    "This shows the most simple code to do so, but many of the functions have additional features, so please check out the docs on GitHub.\n",
    "\n",
    "Mathis et al, in prep. <- please note, we are providing this toolbox as an early access release; more feeatures and details will be released with the forthcoming paper.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txoddlM8hLKm"
   },
   "source": [
    "## First, go to \"Runtime\" ->\"change runtime type\"->select \"Python3\", and then select \"GPU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oTwAcbq2-FZz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-03 15:35:37.970994: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-03 15:35:38.239022: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-03 15:35:38.239040: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-03 15:35:38.275783: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-03 15:35:39.203615: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-03 15:35:39.203689: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-03 15:35:39.203696: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.2.2...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nvers = (tf.__version__).split(\".\")\\nif int(vers[0]) == 1 and int(vers[1]) > 12:\\n    TF = tf.compat.v1  # behaves differently before 1.13\\nelse:\\n    TF = tf\\n\\nTF.logging.set_verbosity(TF.logging.ERROR)\\nDEBUG = True and \"DEBUG\" in os.environ and os.environ[\"DEBUG\"]\\nfrom deeplabcut import DEBUG\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GUIs don't work on the cloud, so we supress them:\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "#os.environ[\"DLClight\"]=\"True\"\n",
    "import deeplabcut\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's make sure we see a GPU:\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Frnj1RVDyEqs"
   },
   "source": [
    "## YOU WILL NEED TO EDIT THE PROJECT PATH **in the config.yaml file** TO BE SET TO YOUR GOOGLE DRIVE LINK!\n",
    "\n",
    "Typically, this will be: /content/drive/My Drive/yourProjectFolderName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vhENAlQnFENJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/config.yaml'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE EDIT THIS:\n",
    "ProjectFolderName = 'Cricket20-Yuchen-2022-08-22'\n",
    "VideoType = 'mp4' #, mp4, MOV, or avi, whatever you uploaded!\n",
    "\n",
    "\n",
    "# we are going to assume you put videos you want to analyze in the \"videos\" folder, but if this is NOT true, edit below:\n",
    "videofile_path = ['/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/videos/'] #Enter the list of videos or folder to analyze.\n",
    "videofile_path\n",
    "\n",
    "\n",
    "#No need to edit this, as you set it when you passed the ProjectFolderName (above): \n",
    "path_config_file = '/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/config.yaml'\n",
    "path_config_file\n",
    "#This creates a path variable that links to your google drive copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a multi-animal training dataset:\n",
    "### You must do this step inside of Colab:\n",
    "\n",
    "- Reminder: you must connect EVERY bodypart in a skeleton before you run this step! See docs for crucial details on how to do this effciently: https://github.com/DeepLabCut/DeepLabCut/blob/master/docs/functionDetails.md#b-configure-the-project-\n",
    "\n",
    "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1589256735280-SCN7CROSJNJWCDS6EK5T/ke17ZwdGBToddI8pDm48kB08p9-rNkpPD7A3fw8YFjZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIno0kSvzOWihTW1zp8-1-7mzYxUQjsVr2n3nmNdVcso4/bodyparts-skeleton.png?format=1000w)\n",
    "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1589410182515-9SJO9MML6CNCXBAWQ6Z6/ke17ZwdGBToddI8pDm48kJ1oJoOIxBAgRD2ClXVCmKFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxBw7VlGKDQO2xTcc51Yv6DahHgScLwHgvMZoEtbzk_9vMJY_JknNFgVzVQ2g0FD_s/ezgif.com-video-to-gif+%2811%29.gif?format=750w)\n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#deeplabcut.cropimagesandlabels(path_config_file, size=(400, 400), userfeedback=False)\n",
    "deeplabcut.add_new_videos(path_config_file, ['/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/videos/PIC_0637.mp4',\n",
    "                                             '/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/videos/PIC_0638.mp4',\n",
    "                                             '/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/videos/PIC_0639.mp4',\n",
    "                                             '/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/videos/PIC_0640.mp4',\n",
    "                                             '/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/videos/PIC_0641.mp4',\n",
    "                                             '/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/videos/PIC_0642.mp4'], copy_videos=False)\n",
    "#if you labeled on Windows, please set the windows2linux=True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.extract_frames(path_config_file, mode='automatic', algo='kmeans', userfeedback=False, crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.label_frames(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.check_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.SkeletonBuilder(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 15:36:04.427: Failed to load module \"canberra-gtk-module\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/deeplabcut/gui/refinement.py:736: FutureWarning: inplace is deprecated and will be removed in a future version.\n",
      "  [self.scorer.replace(self.scorer, self.humanscorer)], level=0, inplace=True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/deeplabcut/generate_training_dataset/trainingsetmanipulation.py:823: FutureWarning: `windows2linux` has no effect since 2.2.0.4 and will be removed in 2.2.1.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading a ImageNet-pretrained model from http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz....\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([106,   7, 125, 160, 136,  71,  56, 151, 162, 108,  33, 153, 158,\n",
       "            5,  18,  92, 164, 143,  37, 101, 144,  60,  63,   4, 122, 165,\n",
       "          113, 166, 168,  61,  44,  26, 107, 131,  66,   8,  55,  83,  45,\n",
       "          163, 123,  24,  30,  95,  54,  80,  19, 137, 104, 146,  16,  51,\n",
       "          170, 121,  40,  74,  22, 110, 111, 129,  96,  90, 116,  27,  94,\n",
       "          157, 130, 176,  89,  62,   2,  59,  97,  98,  43,  10,  86,  73,\n",
       "          173, 161, 112, 138,  93, 150, 179,  50, 177, 118,  64, 124, 126,\n",
       "           69,  49,  48,  85,  13, 135,  23, 167,  20,  15,  78,  52, 100,\n",
       "           76,   3, 178, 109,   6,  68,  75,  84, 134,  12, 139, 154,  14,\n",
       "            0,  91, 155,  46,  11, 119, 102,  35,  57,  41, 175,  65,   1,\n",
       "          120, 145,  42, 105, 132, 156,  17,  38, 133,  53, 141, 128,  34,\n",
       "           28, 114,  31, 149, 127, 159,  32, 142, 152, 147,  29,  99,  82,\n",
       "           79, 115, 148, 174,  72,  77,  25,  81, 169, 171,  39,  58, 140,\n",
       "           88,  70]),\n",
       "   array([ 87,  36,  21,   9, 103,  67, 117,  47, 172])))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file, augmenter_type='imgaug', windows2linux=True)\n",
    "#deeplabcut.create_multianimaltraining_dataset(path_config_file, windows2linux=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training:\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_pOvDq_2oEJW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15],\n",
      "                [16],\n",
      "                [17],\n",
      "                [18],\n",
      "                [19],\n",
      "                [20],\n",
      "                [21],\n",
      "                [22],\n",
      "                [23],\n",
      "                [24]],\n",
      " 'all_joints_names': ['Head',\n",
      "                      'Pro',\n",
      "                      'Meso',\n",
      "                      'Meta',\n",
      "                      'LF0',\n",
      "                      'LF1',\n",
      "                      'LF2',\n",
      "                      'LM0',\n",
      "                      'LM1',\n",
      "                      'LM2',\n",
      "                      'LH0',\n",
      "                      'LH1',\n",
      "                      'LH2',\n",
      "                      'RF0',\n",
      "                      'RF1',\n",
      "                      'RF2',\n",
      "                      'RM0',\n",
      "                      'RM1',\n",
      "                      'RM2',\n",
      "                      'RH0',\n",
      "                      'RH1',\n",
      "                      'RH2',\n",
      "                      'Bar',\n",
      "                      'Axis',\n",
      "                      'Fix'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'contrast': {'clahe': True,\n",
      "              'claheratio': 0.1,\n",
      "              'histeq': True,\n",
      "              'histeqratio': 0.1},\n",
      " 'convolution': {'edge': False,\n",
      "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
      "                 'embossratio': 0.1,\n",
      "                 'sharpen': False,\n",
      "                 'sharpenratio': 0.3},\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_CricketAug22/Cricket_Pranav95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_CricketAug22/Documentation_data-Cricket_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 25,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/dlc-models/iteration-0/CricketAug22-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Batch Size is 1\n",
      "Loading ImageNet-pretrained resnet_50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-19 12:56:54.863162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA RTX A6000 major: 8 minor: 6 memoryClockRate(GHz): 1.8\n",
      "pciBusID: 0000:a1:00.0\n",
      "2022-09-19 12:56:54.863381: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/cv2/../../lib64:/opt/slurm/20.02.6/lib\n",
      "2022-09-19 12:56:54.863444: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/cv2/../../lib64:/opt/slurm/20.02.6/lib\n",
      "2022-09-19 12:56:54.863506: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/cv2/../../lib64:/opt/slurm/20.02.6/lib\n",
      "2022-09-19 12:56:54.863565: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/cv2/../../lib64:/opt/slurm/20.02.6/lib\n",
      "2022-09-19 12:56:54.863626: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/cv2/../../lib64:/opt/slurm/20.02.6/lib\n",
      "2022-09-19 12:56:54.863682: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/cv2/../../lib64:/opt/slurm/20.02.6/lib\n",
      "2022-09-19 12:56:54.863744: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/cv2/../../lib64:/opt/slurm/20.02.6/lib\n",
      "2022-09-19 12:56:54.863750: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-19 12:56:54.863763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-09-19 12:56:54.863767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2022-09-19 12:56:54.863771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_iters overwritten as 300000\n",
      "Display_iters overwritten as 1000\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/dlc-models/iteration-0/CricketAug22-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15], [16], [17], [18], [19], [20], [21], [22], [23], [24]], 'all_joints_names': ['Head', 'Pro', 'Meso', 'Meta', 'LF0', 'LF1', 'LF2', 'LM0', 'LM1', 'LM2', 'LH0', 'LH1', 'LH2', 'RF0', 'RF1', 'RF2', 'RM0', 'RM1', 'RM2', 'RH0', 'RH1', 'RH2', 'Bar', 'Axis', 'Fix'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'contrast': {'clahe': True, 'claheratio': 0.1, 'histeq': True, 'histeqratio': 0.1, 'gamma': False, 'sigmoid': False, 'log': False, 'linear': False}, 'convolution': {'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]}, 'embossratio': 0.1, 'sharpen': False, 'sharpenratio': 0.3}, 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_CricketAug22/Cricket_Pranav95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': '/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_CricketAug22/Documentation_data-Cricket_95shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 25, 'pos_dist_thresh': 17, 'project_path': '/home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000 loss: 0.0354 lr: 0.005\n",
      "iteration: 2000 loss: 0.0204 lr: 0.005\n",
      "iteration: 3000 loss: 0.0167 lr: 0.005\n",
      "iteration: 4000 loss: 0.0145 lr: 0.005\n",
      "iteration: 5000 loss: 0.0135 lr: 0.005\n",
      "iteration: 6000 loss: 0.0122 lr: 0.005\n",
      "iteration: 7000 loss: 0.0114 lr: 0.005\n",
      "iteration: 8000 loss: 0.0109 lr: 0.005\n",
      "iteration: 9000 loss: 0.0104 lr: 0.005\n",
      "iteration: 10000 loss: 0.0099 lr: 0.005\n",
      "iteration: 11000 loss: 0.0110 lr: 0.02\n",
      "iteration: 12000 loss: 0.0099 lr: 0.02\n",
      "iteration: 13000 loss: 0.0088 lr: 0.02\n",
      "iteration: 14000 loss: 0.0082 lr: 0.02\n",
      "iteration: 15000 loss: 0.0076 lr: 0.02\n",
      "iteration: 16000 loss: 0.0074 lr: 0.02\n",
      "iteration: 17000 loss: 0.0070 lr: 0.02\n",
      "iteration: 18000 loss: 0.0066 lr: 0.02\n",
      "iteration: 19000 loss: 0.0065 lr: 0.02\n",
      "iteration: 20000 loss: 0.0063 lr: 0.02\n",
      "iteration: 21000 loss: 0.0062 lr: 0.02\n",
      "iteration: 22000 loss: 0.0060 lr: 0.02\n",
      "iteration: 23000 loss: 0.0059 lr: 0.02\n",
      "iteration: 24000 loss: 0.0057 lr: 0.02\n",
      "iteration: 25000 loss: 0.0056 lr: 0.02\n",
      "iteration: 26000 loss: 0.0055 lr: 0.02\n",
      "iteration: 27000 loss: 0.0055 lr: 0.02\n",
      "iteration: 28000 loss: 0.0054 lr: 0.02\n",
      "iteration: 29000 loss: 0.0053 lr: 0.02\n",
      "iteration: 30000 loss: 0.0052 lr: 0.02\n",
      "iteration: 31000 loss: 0.0053 lr: 0.02\n",
      "iteration: 32000 loss: 0.0052 lr: 0.02\n",
      "iteration: 33000 loss: 0.0051 lr: 0.02\n",
      "iteration: 34000 loss: 0.0051 lr: 0.02\n",
      "iteration: 35000 loss: 0.0050 lr: 0.02\n",
      "iteration: 36000 loss: 0.0048 lr: 0.02\n",
      "iteration: 37000 loss: 0.0049 lr: 0.02\n",
      "iteration: 38000 loss: 0.0048 lr: 0.02\n",
      "iteration: 39000 loss: 0.0047 lr: 0.02\n",
      "iteration: 40000 loss: 0.0046 lr: 0.02\n",
      "iteration: 41000 loss: 0.0047 lr: 0.02\n",
      "iteration: 42000 loss: 0.0046 lr: 0.02\n",
      "iteration: 43000 loss: 0.0046 lr: 0.02\n",
      "iteration: 44000 loss: 0.0045 lr: 0.02\n",
      "iteration: 45000 loss: 0.0046 lr: 0.02\n",
      "iteration: 46000 loss: 0.0046 lr: 0.02\n",
      "iteration: 47000 loss: 0.0044 lr: 0.02\n",
      "iteration: 48000 loss: 0.0044 lr: 0.02\n",
      "iteration: 49000 loss: 0.0044 lr: 0.02\n",
      "iteration: 50000 loss: 0.0043 lr: 0.02\n",
      "iteration: 51000 loss: 0.0042 lr: 0.02\n",
      "iteration: 52000 loss: 0.0043 lr: 0.02\n",
      "iteration: 53000 loss: 0.0042 lr: 0.02\n",
      "iteration: 54000 loss: 0.0042 lr: 0.02\n",
      "iteration: 55000 loss: 0.0041 lr: 0.02\n",
      "iteration: 56000 loss: 0.0041 lr: 0.02\n",
      "iteration: 57000 loss: 0.0040 lr: 0.02\n",
      "iteration: 58000 loss: 0.0040 lr: 0.02\n",
      "iteration: 59000 loss: 0.0039 lr: 0.02\n",
      "iteration: 60000 loss: 0.0039 lr: 0.02\n",
      "iteration: 61000 loss: 0.0040 lr: 0.02\n",
      "iteration: 62000 loss: 0.0039 lr: 0.02\n",
      "iteration: 63000 loss: 0.0039 lr: 0.02\n",
      "iteration: 64000 loss: 0.0039 lr: 0.02\n",
      "iteration: 65000 loss: 0.0038 lr: 0.02\n",
      "iteration: 66000 loss: 0.0038 lr: 0.02\n",
      "iteration: 67000 loss: 0.0038 lr: 0.02\n",
      "iteration: 68000 loss: 0.0037 lr: 0.02\n",
      "iteration: 69000 loss: 0.0037 lr: 0.02\n",
      "iteration: 70000 loss: 0.0037 lr: 0.02\n",
      "iteration: 71000 loss: 0.0037 lr: 0.02\n",
      "iteration: 72000 loss: 0.0037 lr: 0.02\n",
      "iteration: 73000 loss: 0.0037 lr: 0.02\n",
      "iteration: 74000 loss: 0.0037 lr: 0.02\n",
      "iteration: 75000 loss: 0.0036 lr: 0.02\n",
      "iteration: 76000 loss: 0.0036 lr: 0.02\n",
      "iteration: 77000 loss: 0.0036 lr: 0.02\n",
      "iteration: 78000 loss: 0.0036 lr: 0.02\n",
      "iteration: 79000 loss: 0.0036 lr: 0.02\n",
      "iteration: 80000 loss: 0.0036 lr: 0.02\n",
      "iteration: 81000 loss: 0.0036 lr: 0.02\n",
      "iteration: 82000 loss: 0.0036 lr: 0.02\n",
      "iteration: 83000 loss: 0.0035 lr: 0.02\n",
      "iteration: 84000 loss: 0.0035 lr: 0.02\n",
      "iteration: 85000 loss: 0.0035 lr: 0.02\n",
      "iteration: 86000 loss: 0.0035 lr: 0.02\n",
      "iteration: 87000 loss: 0.0035 lr: 0.02\n",
      "iteration: 88000 loss: 0.0034 lr: 0.02\n",
      "iteration: 89000 loss: 0.0035 lr: 0.02\n",
      "iteration: 90000 loss: 0.0035 lr: 0.02\n",
      "iteration: 91000 loss: 0.0035 lr: 0.02\n",
      "iteration: 92000 loss: 0.0034 lr: 0.02\n",
      "iteration: 93000 loss: 0.0034 lr: 0.02\n",
      "iteration: 94000 loss: 0.0034 lr: 0.02\n",
      "iteration: 95000 loss: 0.0035 lr: 0.02\n",
      "iteration: 96000 loss: 0.0034 lr: 0.02\n",
      "iteration: 97000 loss: 0.0034 lr: 0.02\n",
      "iteration: 98000 loss: 0.0034 lr: 0.02\n",
      "iteration: 99000 loss: 0.0034 lr: 0.02\n",
      "iteration: 100000 loss: 0.0033 lr: 0.02\n",
      "iteration: 101000 loss: 0.0033 lr: 0.02\n",
      "iteration: 102000 loss: 0.0034 lr: 0.02\n",
      "iteration: 103000 loss: 0.0034 lr: 0.02\n",
      "iteration: 104000 loss: 0.0033 lr: 0.02\n",
      "iteration: 105000 loss: 0.0033 lr: 0.02\n",
      "iteration: 106000 loss: 0.0033 lr: 0.02\n",
      "iteration: 107000 loss: 0.0033 lr: 0.02\n",
      "iteration: 108000 loss: 0.0033 lr: 0.02\n",
      "iteration: 109000 loss: 0.0033 lr: 0.02\n",
      "iteration: 110000 loss: 0.0032 lr: 0.02\n",
      "iteration: 111000 loss: 0.0032 lr: 0.02\n",
      "iteration: 112000 loss: 0.0032 lr: 0.02\n",
      "iteration: 113000 loss: 0.0032 lr: 0.02\n",
      "iteration: 114000 loss: 0.0033 lr: 0.02\n",
      "iteration: 115000 loss: 0.0032 lr: 0.02\n",
      "iteration: 116000 loss: 0.0032 lr: 0.02\n",
      "iteration: 117000 loss: 0.0032 lr: 0.02\n",
      "iteration: 118000 loss: 0.0032 lr: 0.02\n",
      "iteration: 119000 loss: 0.0032 lr: 0.02\n",
      "iteration: 120000 loss: 0.0032 lr: 0.02\n",
      "iteration: 121000 loss: 0.0031 lr: 0.02\n",
      "iteration: 122000 loss: 0.0032 lr: 0.02\n",
      "iteration: 123000 loss: 0.0031 lr: 0.02\n",
      "iteration: 124000 loss: 0.0032 lr: 0.02\n",
      "iteration: 125000 loss: 0.0032 lr: 0.02\n",
      "iteration: 126000 loss: 0.0031 lr: 0.02\n",
      "iteration: 127000 loss: 0.0031 lr: 0.02\n",
      "iteration: 128000 loss: 0.0031 lr: 0.02\n",
      "iteration: 129000 loss: 0.0031 lr: 0.02\n",
      "iteration: 130000 loss: 0.0031 lr: 0.02\n",
      "iteration: 131000 loss: 0.0031 lr: 0.02\n",
      "iteration: 132000 loss: 0.0031 lr: 0.02\n",
      "iteration: 133000 loss: 0.0031 lr: 0.02\n",
      "iteration: 134000 loss: 0.0031 lr: 0.02\n",
      "iteration: 135000 loss: 0.0031 lr: 0.02\n",
      "iteration: 136000 loss: 0.0031 lr: 0.02\n",
      "iteration: 137000 loss: 0.0030 lr: 0.02\n",
      "iteration: 138000 loss: 0.0030 lr: 0.02\n",
      "iteration: 139000 loss: 0.0031 lr: 0.02\n",
      "iteration: 140000 loss: 0.0030 lr: 0.02\n",
      "iteration: 141000 loss: 0.0030 lr: 0.02\n",
      "iteration: 142000 loss: 0.0030 lr: 0.02\n",
      "iteration: 143000 loss: 0.0030 lr: 0.02\n",
      "iteration: 144000 loss: 0.0030 lr: 0.02\n",
      "iteration: 145000 loss: 0.0030 lr: 0.02\n",
      "iteration: 146000 loss: 0.0030 lr: 0.02\n",
      "iteration: 147000 loss: 0.0030 lr: 0.02\n",
      "iteration: 148000 loss: 0.0030 lr: 0.02\n",
      "iteration: 149000 loss: 0.0030 lr: 0.02\n",
      "iteration: 150000 loss: 0.0030 lr: 0.02\n",
      "iteration: 151000 loss: 0.0030 lr: 0.02\n",
      "iteration: 152000 loss: 0.0030 lr: 0.02\n",
      "iteration: 153000 loss: 0.0030 lr: 0.02\n",
      "iteration: 154000 loss: 0.0030 lr: 0.02\n",
      "iteration: 155000 loss: 0.0029 lr: 0.02\n",
      "iteration: 156000 loss: 0.0030 lr: 0.02\n",
      "iteration: 157000 loss: 0.0029 lr: 0.02\n",
      "iteration: 158000 loss: 0.0030 lr: 0.02\n",
      "iteration: 159000 loss: 0.0030 lr: 0.02\n",
      "iteration: 160000 loss: 0.0029 lr: 0.02\n",
      "iteration: 161000 loss: 0.0029 lr: 0.02\n",
      "iteration: 162000 loss: 0.0029 lr: 0.02\n",
      "iteration: 163000 loss: 0.0029 lr: 0.02\n",
      "iteration: 164000 loss: 0.0029 lr: 0.02\n",
      "iteration: 165000 loss: 0.0029 lr: 0.02\n",
      "iteration: 166000 loss: 0.0029 lr: 0.02\n",
      "iteration: 167000 loss: 0.0029 lr: 0.02\n",
      "iteration: 168000 loss: 0.0030 lr: 0.02\n",
      "iteration: 169000 loss: 0.0029 lr: 0.02\n",
      "iteration: 170000 loss: 0.0029 lr: 0.02\n",
      "iteration: 171000 loss: 0.0029 lr: 0.02\n",
      "iteration: 172000 loss: 0.0029 lr: 0.02\n",
      "iteration: 173000 loss: 0.0029 lr: 0.02\n",
      "iteration: 174000 loss: 0.0029 lr: 0.02\n",
      "iteration: 175000 loss: 0.0028 lr: 0.02\n",
      "iteration: 176000 loss: 0.0029 lr: 0.02\n",
      "iteration: 177000 loss: 0.0029 lr: 0.02\n",
      "iteration: 178000 loss: 0.0029 lr: 0.02\n",
      "iteration: 179000 loss: 0.0029 lr: 0.02\n",
      "iteration: 180000 loss: 0.0029 lr: 0.02\n",
      "iteration: 181000 loss: 0.0029 lr: 0.02\n",
      "iteration: 182000 loss: 0.0029 lr: 0.02\n",
      "iteration: 183000 loss: 0.0028 lr: 0.02\n",
      "iteration: 184000 loss: 0.0028 lr: 0.02\n",
      "iteration: 185000 loss: 0.0028 lr: 0.02\n",
      "iteration: 186000 loss: 0.0029 lr: 0.02\n",
      "iteration: 187000 loss: 0.0028 lr: 0.02\n",
      "iteration: 188000 loss: 0.0028 lr: 0.02\n",
      "iteration: 189000 loss: 0.0028 lr: 0.02\n",
      "iteration: 190000 loss: 0.0028 lr: 0.02\n",
      "iteration: 191000 loss: 0.0028 lr: 0.02\n",
      "iteration: 192000 loss: 0.0028 lr: 0.02\n",
      "iteration: 193000 loss: 0.0027 lr: 0.02\n",
      "iteration: 194000 loss: 0.0028 lr: 0.02\n",
      "iteration: 195000 loss: 0.0028 lr: 0.02\n",
      "iteration: 196000 loss: 0.0028 lr: 0.02\n",
      "iteration: 197000 loss: 0.0028 lr: 0.02\n",
      "iteration: 198000 loss: 0.0027 lr: 0.02\n",
      "iteration: 199000 loss: 0.0028 lr: 0.02\n",
      "iteration: 200000 loss: 0.0028 lr: 0.02\n",
      "iteration: 201000 loss: 0.0028 lr: 0.02\n",
      "iteration: 202000 loss: 0.0028 lr: 0.02\n",
      "iteration: 203000 loss: 0.0027 lr: 0.02\n",
      "iteration: 204000 loss: 0.0028 lr: 0.02\n",
      "iteration: 205000 loss: 0.0027 lr: 0.02\n",
      "iteration: 206000 loss: 0.0027 lr: 0.02\n",
      "iteration: 207000 loss: 0.0027 lr: 0.02\n",
      "iteration: 208000 loss: 0.0027 lr: 0.02\n",
      "iteration: 209000 loss: 0.0027 lr: 0.02\n",
      "iteration: 210000 loss: 0.0027 lr: 0.02\n",
      "iteration: 211000 loss: 0.0026 lr: 0.02\n",
      "iteration: 212000 loss: 0.0026 lr: 0.02\n",
      "iteration: 213000 loss: 0.0026 lr: 0.02\n",
      "iteration: 214000 loss: 0.0027 lr: 0.02\n",
      "iteration: 215000 loss: 0.0027 lr: 0.02\n",
      "iteration: 216000 loss: 0.0027 lr: 0.02\n",
      "iteration: 217000 loss: 0.0027 lr: 0.02\n",
      "iteration: 218000 loss: 0.0027 lr: 0.02\n",
      "iteration: 219000 loss: 0.0026 lr: 0.02\n",
      "iteration: 220000 loss: 0.0026 lr: 0.02\n",
      "iteration: 221000 loss: 0.0026 lr: 0.02\n",
      "iteration: 222000 loss: 0.0026 lr: 0.02\n",
      "iteration: 223000 loss: 0.0026 lr: 0.02\n",
      "iteration: 224000 loss: 0.0026 lr: 0.02\n",
      "iteration: 225000 loss: 0.0026 lr: 0.02\n",
      "iteration: 226000 loss: 0.0026 lr: 0.02\n",
      "iteration: 227000 loss: 0.0026 lr: 0.02\n",
      "iteration: 228000 loss: 0.0026 lr: 0.02\n",
      "iteration: 229000 loss: 0.0025 lr: 0.02\n",
      "iteration: 230000 loss: 0.0025 lr: 0.02\n",
      "iteration: 231000 loss: 0.0026 lr: 0.02\n",
      "iteration: 232000 loss: 0.0025 lr: 0.02\n",
      "iteration: 233000 loss: 0.0025 lr: 0.02\n",
      "iteration: 234000 loss: 0.0025 lr: 0.02\n",
      "iteration: 235000 loss: 0.0026 lr: 0.02\n",
      "iteration: 236000 loss: 0.0025 lr: 0.02\n",
      "iteration: 237000 loss: 0.0025 lr: 0.02\n",
      "iteration: 238000 loss: 0.0025 lr: 0.02\n",
      "iteration: 239000 loss: 0.0025 lr: 0.02\n",
      "iteration: 240000 loss: 0.0025 lr: 0.02\n",
      "iteration: 241000 loss: 0.0025 lr: 0.02\n",
      "iteration: 242000 loss: 0.0025 lr: 0.02\n",
      "iteration: 243000 loss: 0.0025 lr: 0.02\n",
      "iteration: 244000 loss: 0.0024 lr: 0.02\n",
      "iteration: 245000 loss: 0.0025 lr: 0.02\n",
      "iteration: 246000 loss: 0.0025 lr: 0.02\n",
      "iteration: 247000 loss: 0.0024 lr: 0.02\n",
      "iteration: 248000 loss: 0.0024 lr: 0.02\n",
      "iteration: 249000 loss: 0.0025 lr: 0.02\n",
      "iteration: 250000 loss: 0.0025 lr: 0.02\n",
      "iteration: 251000 loss: 0.0025 lr: 0.02\n",
      "iteration: 252000 loss: 0.0024 lr: 0.02\n",
      "iteration: 253000 loss: 0.0025 lr: 0.02\n",
      "iteration: 254000 loss: 0.0025 lr: 0.02\n",
      "iteration: 255000 loss: 0.0025 lr: 0.02\n",
      "iteration: 256000 loss: 0.0024 lr: 0.02\n",
      "iteration: 257000 loss: 0.0024 lr: 0.02\n",
      "iteration: 258000 loss: 0.0024 lr: 0.02\n",
      "iteration: 259000 loss: 0.0024 lr: 0.02\n",
      "iteration: 260000 loss: 0.0025 lr: 0.02\n",
      "iteration: 261000 loss: 0.0025 lr: 0.02\n",
      "iteration: 262000 loss: 0.0024 lr: 0.02\n",
      "iteration: 263000 loss: 0.0024 lr: 0.02\n",
      "iteration: 264000 loss: 0.0024 lr: 0.02\n",
      "iteration: 265000 loss: 0.0023 lr: 0.02\n",
      "iteration: 266000 loss: 0.0024 lr: 0.02\n",
      "iteration: 267000 loss: 0.0024 lr: 0.02\n",
      "iteration: 268000 loss: 0.0024 lr: 0.02\n",
      "iteration: 269000 loss: 0.0024 lr: 0.02\n",
      "iteration: 270000 loss: 0.0024 lr: 0.02\n",
      "iteration: 271000 loss: 0.0024 lr: 0.02\n",
      "iteration: 272000 loss: 0.0024 lr: 0.02\n",
      "iteration: 273000 loss: 0.0024 lr: 0.02\n",
      "iteration: 274000 loss: 0.0023 lr: 0.02\n",
      "iteration: 275000 loss: 0.0024 lr: 0.02\n",
      "iteration: 276000 loss: 0.0024 lr: 0.02\n",
      "iteration: 277000 loss: 0.0024 lr: 0.02\n",
      "iteration: 278000 loss: 0.0024 lr: 0.02\n",
      "iteration: 279000 loss: 0.0024 lr: 0.02\n",
      "iteration: 280000 loss: 0.0024 lr: 0.02\n",
      "iteration: 281000 loss: 0.0023 lr: 0.02\n",
      "iteration: 282000 loss: 0.0024 lr: 0.02\n",
      "iteration: 283000 loss: 0.0023 lr: 0.02\n",
      "iteration: 284000 loss: 0.0023 lr: 0.02\n",
      "iteration: 285000 loss: 0.0023 lr: 0.02\n",
      "iteration: 286000 loss: 0.0023 lr: 0.02\n",
      "iteration: 287000 loss: 0.0023 lr: 0.02\n",
      "iteration: 288000 loss: 0.0023 lr: 0.02\n",
      "iteration: 289000 loss: 0.0023 lr: 0.02\n",
      "iteration: 290000 loss: 0.0023 lr: 0.02\n",
      "iteration: 291000 loss: 0.0023 lr: 0.02\n",
      "iteration: 292000 loss: 0.0023 lr: 0.02\n",
      "iteration: 293000 loss: 0.0024 lr: 0.02\n",
      "iteration: 294000 loss: 0.0023 lr: 0.02\n",
      "iteration: 295000 loss: 0.0023 lr: 0.02\n",
      "iteration: 296000 loss: 0.0023 lr: 0.02\n",
      "iteration: 297000 loss: 0.0023 lr: 0.02\n",
      "iteration: 298000 loss: 0.0023 lr: 0.02\n",
      "iteration: 299000 loss: 0.0023 lr: 0.02\n",
      "iteration: 300000 loss: 0.0023 lr: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 11:51:36.232555: W tensorflow/core/kernels/queue_base.cc:277] _0_fifo_queue: Skipping cancelled enqueue attempt with queue not closed\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
      "    target_list, run_metadata)\n",
      "  File \"/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 83, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n",
      "\n",
      "Original stack trace for 'fifo_queue_enqueue':\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/traitlets/config/application.py\", line 978, in launch_instance\n",
      "    app.start()\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/asyncio/base_events.py\", line 538, in run_forever\n",
      "    self._run_once()\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/asyncio/base_events.py\", line 1782, in _run_once\n",
      "    handle._run()\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 387, in do_execute\n",
      "    cell_id=cell_id,\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2976, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures, cell_id\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3258, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"tmp/ipykernel_27462/3618215437.py\", line 8, in <module>\n",
      "    deeplabcut.train_network(path_config_file, shuffle=shuffle, displayiters=1000, saveiters=1000, maxiters=300000)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\", line 217, in train_network\n",
      "    allow_growth=allow_growth,\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 168, in train\n",
      "    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py\", line 69, in setup_preloading\n",
      "    enqueue_op = q.enqueue(placeholders_list)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/ops/data_flow_ops.py\", line 346, in enqueue\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_data_flow_ops.py\", line 4410, in queue_enqueue_v2\n",
      "    timeout_ms=timeout_ms, name=name)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n",
      "    attrs, op_def, compute_device)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#let's also change the display and save_iters just in case Colab takes away the GPU... \n",
    "#if that happens, you can reload from a saved point. \n",
    "#Typically, you want to train to 50,000 iterations.\n",
    "#more info and there are more things you can set: https://github.com/AlexEMG/DeepLabCut/blob/master/docs/functionDetails.md#g-train-the-network\n",
    "\n",
    "#which shuffle do you want to train?\n",
    "shuffle = 1\n",
    "deeplabcut.train_network(path_config_file, shuffle=shuffle, displayiters=1000, saveiters=1000, maxiters=300000)\n",
    "\n",
    "#this will run until you stop it (CTRL+C), or hit \"STOP\" icon, or when it hits the end (default, 50K iterations). \n",
    "#Whichever you chose, you will see what looks like an error message, but it's not an error - don't worry...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiDwIVf5-3H_"
   },
   "source": [
    "**When you hit \"STOP\" you will get a KeyInterrupt \"error\"! No worries! :)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating: for maDLC, this is several steps. \n",
    " - First, we evaluate the pose estimation performance, and then we can cross-valudate optimal inference parameters.\n",
    "\n",
    "- This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images) and stores the results as .5 and .csv file in a subdirectory under **evaluation-results**\n",
    "\n",
    "- If the scoremaps do not look accurate, don't proceed to tracklet assembly; please consider (1) adding more data, (2) adding more bodyparts!\n",
    "\n",
    "Here is an example of what you'd aim to see before proceeding:\n",
    "\n",
    "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1590535809087-X655WY9W1MW1MY1I7DHE/ke17ZwdGBToddI8pDm48kBoswZhKnUtAF7-bTXgw67EUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc5tTP1cnANTUwNNPnYFjIp6XbP9N1GxIgAkxvBVqt0UvLpPHYwvNQTwHg8f_Zu8ZF/evaluation.png?format=1000w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nv4zlbrnoEJg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15],\n",
      "                [16],\n",
      "                [17],\n",
      "                [18],\n",
      "                [19],\n",
      "                [20],\n",
      "                [21],\n",
      "                [22],\n",
      "                [23],\n",
      "                [24]],\n",
      " 'all_joints_names': ['Head',\n",
      "                      'Pro',\n",
      "                      'Meso',\n",
      "                      'Meta',\n",
      "                      'LF0',\n",
      "                      'LF1',\n",
      "                      'LF2',\n",
      "                      'LM0',\n",
      "                      'LM1',\n",
      "                      'LM2',\n",
      "                      'LH0',\n",
      "                      'LH1',\n",
      "                      'LH2',\n",
      "                      'RF0',\n",
      "                      'RF1',\n",
      "                      'RF2',\n",
      "                      'RM0',\n",
      "                      'RM1',\n",
      "                      'RM2',\n",
      "                      'RH0',\n",
      "                      'RH1',\n",
      "                      'RH2',\n",
      "                      'Bar',\n",
      "                      'Axis',\n",
      "                      'Fix'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_CricketAug22/Cricket_Pranav95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 25,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/dlc-models/iteration-0/CricketAug22-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_resnet50_CricketAug22shuffle1_300000  with # of training iterations: 300000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 11:51:37.750416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA RTX A6000 major: 8 minor: 6 memoryClockRate(GHz): 1.8\n",
      "pciBusID: 0000:a1:00.0\n",
      "2022-09-21 11:51:37.750642: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/cv2/../../lib64:/opt/slurm/20.02.6/lib\n",
      "2022-09-21 11:51:37.750701: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/cv2/../../lib64:/opt/slurm/20.02.6/lib\n",
      "2022-09-21 11:51:37.750757: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/cv2/../../lib64:/opt/slurm/20.02.6/lib\n",
      "2022-09-21 11:51:37.750813: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/cv2/../../lib64:/opt/slurm/20.02.6/lib\n",
      "2022-09-21 11:51:37.750866: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/cv2/../../lib64:/opt/slurm/20.02.6/lib\n",
      "2022-09-21 11:51:37.750920: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/cv2/../../lib64:/opt/slurm/20.02.6/lib\n",
      "2022-09-21 11:51:37.750976: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/cv2/../../lib64:/opt/slurm/20.02.6/lib\n",
      "2022-09-21 11:51:37.750982: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-21 11:51:37.751357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-09-21 11:51:37.751367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [00:32,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis is done and the results are stored (see evaluation-results) for snapshot:  snapshot-300000\n",
      "Results for 300000  training iterations: 95 1 train error: 2.0 pixels. Test error: 3.07  pixels.\n",
      "With pcutoff of 0.4  train error: 2.0 pixels. Test error: 3.07 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "Please check the results, then choose the best model (snapshot) for prediction. You can update the config.yaml file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise, consider adding more labeled-data and retraining the network (see DeepLabCut workflow Fig 2, Nath 2019)\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib notebook\n",
    "#let's evaluate first:\n",
    "%matplotlib inline\n",
    "deeplabcut.evaluate_network(path_config_file,plotting=False)\n",
    "#plot a few scoremaps:\n",
    "#deeplabcut.extract_save_all_maps(path_config_file, shuffle=shuffle, Indices=[0])\n",
    "\n",
    "\n",
    "#and begin to cross-validate:\n",
    "#deeplabcut.evaluate_multianimal_crossvalidate(\n",
    "#            path_config_file,\n",
    "#            Shuffles=[shuffle],\n",
    "#            edgewisecondition=True,\n",
    "#            leastbpts=1,\n",
    "#            init_points=20,\n",
    "#            n_iter=100,\n",
    "#            target='rpck_train',\n",
    "#        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MbIL5z2U7fp"
   },
   "source": [
    "^ NOTE: this optimized part detection for video analysis. It cannot optimze for tracking, as this is use-case dependent. Please check the docs on how you can set the best parameters and modify/test before \"final\" tracking parameters. You can use COLAB to analyze videos, but afterwards we recommend using the outputs/proejct folder locally to run the final steps! They do not require a GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos: \n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12],\n",
      "                [13],\n",
      "                [14],\n",
      "                [15],\n",
      "                [16],\n",
      "                [17],\n",
      "                [18],\n",
      "                [19],\n",
      "                [20],\n",
      "                [21],\n",
      "                [22],\n",
      "                [23],\n",
      "                [24]],\n",
      " 'all_joints_names': ['Head',\n",
      "                      'Pro',\n",
      "                      'Meso',\n",
      "                      'Meta',\n",
      "                      'LF0',\n",
      "                      'LF1',\n",
      "                      'LF2',\n",
      "                      'LM0',\n",
      "                      'LM1',\n",
      "                      'LM2',\n",
      "                      'LH0',\n",
      "                      'LH1',\n",
      "                      'LH2',\n",
      "                      'RF0',\n",
      "                      'RF1',\n",
      "                      'RF2',\n",
      "                      'RM0',\n",
      "                      'RM1',\n",
      "                      'RM2',\n",
      "                      'RH0',\n",
      "                      'RH1',\n",
      "                      'RH2',\n",
      "                      'Bar',\n",
      "                      'Axis',\n",
      "                      'Fix'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_CricketAug22/Cricket_Pranav95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/yuchen/anaconda3/envs/DLC-GPU/lib/python3.7/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 25,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/dlc-models/iteration-0/CricketAug22-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-300000 for model /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/dlc-models/iteration-0/CricketAug22-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-21 11:56:32.852571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-09-21 11:56:32.852635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Starting to analyze %  /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0639.mp4\n",
      "Loading  /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0639.mp4\n",
      "Duration of video [s]:  130.63 , recorded with  59.94 fps!\n",
      "Overall # of frames:  7830  found with (before cropping) frame dimensions:  640 360\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 7800/7830 [15:02<00:03,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0638.mp4\n",
      "Loading  /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0638.mp4\n",
      "Duration of video [s]:  130.38 , recorded with  59.94 fps!\n",
      "Overall # of frames:  7815  found with (before cropping) frame dimensions:  640 360\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 7800/7815 [15:10<00:01,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0641.mp4\n",
      "Loading  /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0641.mp4\n",
      "Duration of video [s]:  131.63 , recorded with  59.94 fps!\n",
      "Overall # of frames:  7890  found with (before cropping) frame dimensions:  640 360\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 7878/7890 [15:24<00:01,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0642.mp4\n",
      "Loading  /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0642.mp4\n",
      "Duration of video [s]:  130.63 , recorded with  59.94 fps!\n",
      "Overall # of frames:  7830  found with (before cropping) frame dimensions:  640 360\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 7800/7830 [15:14<00:03,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0637.mp4\n",
      "Loading  /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0637.mp4\n",
      "Duration of video [s]:  131.13 , recorded with  59.94 fps!\n",
      "Overall # of frames:  7860  found with (before cropping) frame dimensions:  640 360\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 7800/7860 [15:18<00:07,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0640.mp4\n",
      "Loading  /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0640.mp4\n",
      "Duration of video [s]:  130.88 , recorded with  59.94 fps!\n",
      "Overall # of frames:  7845  found with (before cropping) frame dimensions:  640 360\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 7800/7845 [14:17<00:04,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Analyzing all the videos in the directory...\n",
      "Starting to process video: /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0640.mp4Starting to process video: /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0637.mp4Starting to process video: /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0638.mp4Starting to process video: /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0641.mp4\n",
      "\n",
      "Loading /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0640.mp4 and data.Loading /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0637.mp4 and data.Starting to process video: /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0639.mp4\n",
      "Starting to process video: /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0642.mp4\n",
      "\n",
      "\n",
      "Loading /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0638.mp4 and data.\n",
      "Loading /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0641.mp4 and data.\n",
      "\n",
      "Loading /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0639.mp4 and data.\n",
      "\n",
      "Loading /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0642.mp4 and data.\n",
      "Duration of video [s]: 130.88, recorded with 59.94 fps!\n",
      "Overall # of frames: 7845 with cropped frame dimensions: 640 360\n",
      "Generating frames and creating video.\n",
      "Duration of video [s]: 131.63, recorded with 59.94 fps!\n",
      "Overall # of frames: 7890 with cropped frame dimensions: 640 360Duration of video [s]: 130.63, recorded with 59.94 fps!\n",
      "\n",
      "Overall # of frames: 7830 with cropped frame dimensions: 640 360Generating frames and creating video."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7845 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Duration of video [s]: 131.13, recorded with 59.94 fps!\n",
      "Generating frames and creating video.Overall # of frames: 7860 with cropped frame dimensions: 640 360Duration of video [s]: 130.38, recorded with 59.94 fps!\n",
      "\n",
      "\n",
      "Duration of video [s]: 130.63, recorded with 59.94 fps!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7890 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating frames and creating video.Overall # of frames: 7815 with cropped frame dimensions: 640 360\n",
      "\n",
      "\n",
      "Generating frames and creating video.Overall # of frames: 7830 with cropped frame dimensions: 640 360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7830 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7830/7830 [00:31<00:00, 245.74it/s]\n",
      "100%|██████████| 7815/7815 [00:31<00:00, 244.85it/s]\n",
      "100%|██████████| 7845/7845 [00:32<00:00, 244.10it/s]\n",
      "100%|██████████| 7860/7860 [00:32<00:00, 244.61it/s]\n",
      "100%|██████████| 7890/7890 [00:32<00:00, 244.49it/s]\n",
      "100%|██████████| 7830/7830 [00:32<00:00, 242.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory...\n",
      "Processing /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0638.mp4\n",
      "Processing /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0641.mp4\n",
      "Processing /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0640.mp4\n",
      "Processing /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0642.mp4\n",
      "Processing /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0639.mp4\n",
      "Processing /home/yuchen/sftpFolder/DeepLabCut/Cricket20-Yuchen-2022-08-22/videos/PIC_0637.mp4\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.analyze_videos(path_config_file, videofile_path, videotype='.mp4', save_as_csv=True)\n",
    "deeplabcut.create_labeled_video(path_config_file,videofile_path,videotype='.mp4')\n",
    "deeplabcut.analyzeskeleton(path_config_file, videofile_path, videotype='.mp4', shuffle=1, save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(path_config_file, videofile_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "COLAB_maDLC_TrainNetwork_VideoAnalysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('DLC-GPU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d098b461e67d40858732f3fd2b5303d0e007724a75ca61659225288505288e8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
