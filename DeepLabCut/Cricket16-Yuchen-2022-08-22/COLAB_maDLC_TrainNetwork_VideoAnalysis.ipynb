{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MMathisLab/DeepLabCut/blob/master/examples/COLAB_maDLC_TrainNetwork_VideoAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# DeepLabCut 2.2 Toolbox - COLAB\n",
    "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1590444465547-SHXODUII311HEE407IL6/ke17ZwdGBToddI8pDm48kE4VnnB9_j2k1VP236ADqAFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQg9Vf0owGyf3dhfDKy8SxMujaKmp2B54Sb3VS1rO76Whq-cUhHVuKFlGUXsU9tJk/ezgif.com-video-to-gif.gif?format=1500w)\n",
    "\n",
    "https://github.com/DeepLabCut/DeepLabCut\n",
    "\n",
    "This notebook illustrates how to, for multi-animal projects, use the cloud-based GPU to:\n",
    "- create a multi-animal training set\n",
    "- train a network\n",
    "- evaluate a network\n",
    "- cross evaluate inference parameters\n",
    "- analyze novel videos\n",
    "- assemble tracklets\n",
    "- create quality check plots\n",
    "\n",
    "###This notebook assumes you already have a project folder with labeled data! \n",
    "\n",
    "This notebook demonstrates the necessary steps to use DeepLabCut for your own project.\n",
    "\n",
    "This shows the most simple code to do so, but many of the functions have additional features, so please check out the docs on GitHub.\n",
    "\n",
    "Mathis et al, in prep. <- please note, we are providing this toolbox as an early access release; more feeatures and details will be released with the forthcoming paper.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "txoddlM8hLKm"
   },
   "source": [
    "## First, go to \"Runtime\" ->\"change runtime type\"->select \"Python3\", and then select \"GPU\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oTwAcbq2-FZz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.2.2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\__init__.py:85: UserWarning: \n",
      "        As PyTorch is not installed, unsupervised identity learning will not be available.\n",
      "        Please run `pip install torch`, or ignore this warning.\n",
      "        \n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#GUIs don't work on the cloud, so we supress them:\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "#os.environ[\"DLClight\"]=\"True\"\n",
    "import deeplabcut\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Frnj1RVDyEqs"
   },
   "source": [
    "## YOU WILL NEED TO EDIT THE PROJECT PATH **in the config.yaml file** TO BE SET TO YOUR GOOGLE DRIVE LINK!\n",
    "\n",
    "Typically, this will be: /content/drive/My Drive/yourProjectFolderName\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vhENAlQnFENJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sftpFolder/DeepLabCut/Cricket16-Yuchen-2022-08-22/config.yaml'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE EDIT THIS:\n",
    "ProjectFolderName = 'Cricket16-Yuchen-2022-08-22'\n",
    "VideoType = 'mp4' #, mp4, MOV, or avi, whatever you uploaded!\n",
    "\n",
    "\n",
    "# we are going to assume you put videos you want to analyze in the \"videos\" folder, but if this is NOT true, edit below:\n",
    "videofile_path = ['/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/videos/'] #Enter the list of videos or folder to analyze.\n",
    "videofile_path\n",
    "\n",
    "\n",
    "#No need to edit this, as you set it when you passed the ProjectFolderName (above): \n",
    "path_config_file = '/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/config.yaml'\n",
    "path_config_file\n",
    "#This creates a path variable that links to your google drive copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a multi-animal training dataset:\n",
    "### You must do this step inside of Colab:\n",
    "\n",
    "- Reminder: you must connect EVERY bodypart in a skeleton before you run this step! See docs for crucial details on how to do this effciently: https://github.com/DeepLabCut/DeepLabCut/blob/master/docs/functionDetails.md#b-configure-the-project-\n",
    "\n",
    "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1589256735280-SCN7CROSJNJWCDS6EK5T/ke17ZwdGBToddI8pDm48kB08p9-rNkpPD7A3fw8YFjZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIno0kSvzOWihTW1zp8-1-7mzYxUQjsVr2n3nmNdVcso4/bodyparts-skeleton.png?format=1000w)\n",
    "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1589410182515-9SJO9MML6CNCXBAWQ6Z6/ke17ZwdGBToddI8pDm48kJ1oJoOIxBAgRD2ClXVCmKFZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxBw7VlGKDQO2xTcc51Yv6DahHgScLwHgvMZoEtbzk_9vMJY_JknNFgVzVQ2g0FD_s/ezgif.com-video-to-gif+%2811%29.gif?format=750w)\n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n"
     ]
    }
   ],
   "source": [
    "#deeplabcut.cropimagesandlabels(path_config_file, size=(400, 400), userfeedback=False)\n",
    "deeplabcut.add_new_videos(path_config_file, ['/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/videos/PIC_0495.mp4',\n",
    "                                             '/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/videos/PIC_0496.mp4',\n",
    "                                             '/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/videos/PIC_0497.mp4',\n",
    "                                             '/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/videos/PIC_0498.mp4',\n",
    "                                             '/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/videos/PIC_0499.mp4',\n",
    "                                             '/home/yuchen/sftpFolder/DeepLabCut/'+ProjectFolderName+'/videos/PIC_0500.mp4'], copy_videos=False)\n",
    "#if you labeled on Windows, please set the windows2linux=True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:00, 145.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 134.63  seconds.\n",
      "Extracting and downsampling... 8070  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8070it [00:26, 301.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n",
      "34it [00:00, 329.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 133.38  seconds.\n",
      "Extracting and downsampling... 7995  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7995it [00:29, 275.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n",
      "29it [00:00, 287.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 133.13  seconds.\n",
      "Extracting and downsampling... 7980  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7980it [00:25, 311.22it/s]\n",
      "d:\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "70it [00:00, 328.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 147.65  seconds.\n",
      "Extracting and downsampling... 8850  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8850it [00:28, 313.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n",
      "31it [00:00, 301.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 133.88  seconds.\n",
      "Extracting and downsampling... 8025  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8025it [00:27, 295.52it/s]\n",
      "d:\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:00, 308.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting frames based on kmeans ...\n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 136.89  seconds.\n",
      "Extracting and downsampling... 8205  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8205it [00:23, 354.12it/s]\n",
      "d:\\Anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:888: UserWarning: MiniBatchKMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can prevent it by setting batch_size >= 1024 or by setting the environment variable OMP_NUM_THREADS=1\n",
      "  f\"MiniBatchKMeans is known to have a memory leak on \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Frames were successfully extracted, for the videos of interest.\n",
      "\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.extract_frames(path_config_file, mode='automatic', algo='kmeans', userfeedback=False, crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can now check the labels, using 'check_labels' before proceeding. Then, you can use the function 'create_training_dataset' to create the training dataset.\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.label_frames(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.check_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.SkeletonBuilder(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file, augmenter_type='imgaug', windows2linux=True)\n",
    "#deeplabcut.create_multianimaltraining_dataset(path_config_file, windows2linux=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training:\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_pOvDq_2oEJW"
   },
   "outputs": [],
   "source": [
    "#let's also change the display and save_iters just in case Colab takes away the GPU... \n",
    "#if that happens, you can reload from a saved point. \n",
    "#Typically, you want to train to 50,000 iterations.\n",
    "#more info and there are more things you can set: https://github.com/AlexEMG/DeepLabCut/blob/master/docs/functionDetails.md#g-train-the-network\n",
    "\n",
    "#which shuffle do you want to train?\n",
    "shuffle = 1\n",
    "deeplabcut.train_network(path_config_file, shuffle=shuffle, displayiters=1000, saveiters=1000, maxiters=300000)\n",
    "\n",
    "#this will run until you stop it (CTRL+C), or hit \"STOP\" icon, or when it hits the end (default, 50K iterations). \n",
    "#Whichever you chose, you will see what looks like an error message, but it's not an error - don't worry...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiDwIVf5-3H_"
   },
   "source": [
    "**When you hit \"STOP\" you will get a KeyInterrupt \"error\"! No worries! :)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating: for maDLC, this is several steps. \n",
    " - First, we evaluate the pose estimation performance, and then we can cross-valudate optimal inference parameters.\n",
    "\n",
    "- This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images) and stores the results as .5 and .csv file in a subdirectory under **evaluation-results**\n",
    "\n",
    "- If the scoremaps do not look accurate, don't proceed to tracklet assembly; please consider (1) adding more data, (2) adding more bodyparts!\n",
    "\n",
    "Here is an example of what you'd aim to see before proceeding:\n",
    "\n",
    "![alt text](https://images.squarespace-cdn.com/content/v1/57f6d51c9f74566f55ecf271/1590535809087-X655WY9W1MW1MY1I7DHE/ke17ZwdGBToddI8pDm48kBoswZhKnUtAF7-bTXgw67EUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKc5tTP1cnANTUwNNPnYFjIp6XbP9N1GxIgAkxvBVqt0UvLpPHYwvNQTwHg8f_Zu8ZF/evaluation.png?format=1000w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nv4zlbrnoEJg",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "#let's evaluate first:\n",
    "%matplotlib inline\n",
    "deeplabcut.evaluate_network(path_config_file,plotting=False)\n",
    "#plot a few scoremaps:\n",
    "#deeplabcut.extract_save_all_maps(path_config_file, shuffle=shuffle, Indices=[0])\n",
    "\n",
    "\n",
    "#and begin to cross-validate:\n",
    "#deeplabcut.evaluate_multianimal_crossvalidate(\n",
    "#            path_config_file,\n",
    "#            Shuffles=[shuffle],\n",
    "#            edgewisecondition=True,\n",
    "#            leastbpts=1,\n",
    "#            init_points=20,\n",
    "#            n_iter=100,\n",
    "#            target='rpck_train',\n",
    "#        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MbIL5z2U7fp"
   },
   "source": [
    "^ NOTE: this optimized part detection for video analysis. It cannot optimze for tracking, as this is use-case dependent. Please check the docs on how you can set the best parameters and modify/test before \"final\" tracking parameters. You can use COLAB to analyze videos, but afterwards we recommend using the outputs/proejct folder locally to run the final steps! They do not require a GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos: \n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(path_config_file, videofile_path, videotype='.MP4', save_as_csv=True)\n",
    "deeplabcut.create_labeled_video(path_config_file, videofile_path, videotype='.MP4')\n",
    "deeplabcut.analyzeskeleton(path_config_file, videofile_path, videotype='.MP4', shuffle=1, save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames(path_config_file, videofile_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "COLAB_maDLC_TrainNetwork_VideoAnalysis.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 ('DLC-GPU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d098b461e67d40858732f3fd2b5303d0e007724a75ca61659225288505288e8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
